[2025-02-21T13:59:38.368+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: listenbrainz_dynamic_pipeline.list_new_files scheduled__2025-01-01T00:00:00+00:00 [queued]>
[2025-02-21T13:59:38.374+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: listenbrainz_dynamic_pipeline.list_new_files scheduled__2025-01-01T00:00:00+00:00 [queued]>
[2025-02-21T13:59:38.374+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2025-02-21T13:59:38.374+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 2
[2025-02-21T13:59:38.374+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2025-02-21T13:59:38.384+0000] {taskinstance.py:1300} INFO - Executing <Task(_PythonDecoratedOperator): list_new_files> on 2025-01-01 00:00:00+00:00
[2025-02-21T13:59:38.387+0000] {standard_task_runner.py:55} INFO - Started process 232 to run task
[2025-02-21T13:59:38.389+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'listenbrainz_dynamic_pipeline', 'list_new_files', 'scheduled__2025-01-01T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/listenbrainz_dag.py', '--cfg-path', '/tmp/tmpecoor200']
[2025-02-21T13:59:38.390+0000] {standard_task_runner.py:83} INFO - Job 4: Subtask list_new_files
[2025-02-21T13:59:38.440+0000] {task_command.py:388} INFO - Running <TaskInstance: listenbrainz_dynamic_pipeline.list_new_files scheduled__2025-01-01T00:00:00+00:00 [running]> on host ab567731ea96
[2025-02-21T13:59:38.495+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=listenbrainz_dynamic_pipeline
AIRFLOW_CTX_TASK_ID=list_new_files
AIRFLOW_CTX_EXECUTION_DATE=2025-01-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-01-01T00:00:00+00:00
[2025-02-21T13:59:38.495+0000] {listenbrainz_dag.py:47} INFO - Found JSON files: ['/data/raw/sample-data-2.json', '/data/raw/sample-data.json']
[2025-02-21T13:59:38.495+0000] {python.py:177} INFO - Done. Returned value was: ['/data/raw/sample-data-2.json', '/data/raw/sample-data.json']
[2025-02-21T13:59:38.522+0000] {taskinstance.py:1323} INFO - Marking task as SUCCESS. dag_id=listenbrainz_dynamic_pipeline, task_id=list_new_files, execution_date=20250101T000000, start_date=20250221T135938, end_date=20250221T135938
[2025-02-21T13:59:38.561+0000] {local_task_job.py:208} INFO - Task exited with return code 0
[2025-02-21T13:59:38.627+0000] {taskinstance.py:2578} INFO - 2 downstream tasks scheduled from follow-on schedule check
[2025-02-21T14:04:56.249+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: listenbrainz_dynamic_pipeline.list_new_files scheduled__2025-01-01T00:00:00+00:00 [queued]>
[2025-02-21T14:04:56.256+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: listenbrainz_dynamic_pipeline.list_new_files scheduled__2025-01-01T00:00:00+00:00 [queued]>
[2025-02-21T14:04:56.256+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2025-02-21T14:04:56.256+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 2
[2025-02-21T14:04:56.256+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2025-02-21T14:04:56.266+0000] {taskinstance.py:1300} INFO - Executing <Task(_PythonDecoratedOperator): list_new_files> on 2025-01-01 00:00:00+00:00
[2025-02-21T14:04:56.269+0000] {standard_task_runner.py:55} INFO - Started process 232 to run task
[2025-02-21T14:04:56.271+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'listenbrainz_dynamic_pipeline', 'list_new_files', 'scheduled__2025-01-01T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/listenbrainz_dag.py', '--cfg-path', '/tmp/tmp3vk478or']
[2025-02-21T14:04:56.272+0000] {standard_task_runner.py:83} INFO - Job 4: Subtask list_new_files
[2025-02-21T14:04:56.322+0000] {task_command.py:388} INFO - Running <TaskInstance: listenbrainz_dynamic_pipeline.list_new_files scheduled__2025-01-01T00:00:00+00:00 [running]> on host 5b6f74597018
[2025-02-21T14:04:56.379+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=listenbrainz_dynamic_pipeline
AIRFLOW_CTX_TASK_ID=list_new_files
AIRFLOW_CTX_EXECUTION_DATE=2025-01-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-01-01T00:00:00+00:00
[2025-02-21T14:04:56.379+0000] {listenbrainz_dag.py:47} INFO - Found JSON files: ['/data/raw/sample-data-2.json', '/data/raw/sample-data.json']
[2025-02-21T14:04:56.379+0000] {python.py:177} INFO - Done. Returned value was: ['/data/raw/sample-data-2.json', '/data/raw/sample-data.json']
[2025-02-21T14:04:56.404+0000] {taskinstance.py:1323} INFO - Marking task as SUCCESS. dag_id=listenbrainz_dynamic_pipeline, task_id=list_new_files, execution_date=20250101T000000, start_date=20250221T140456, end_date=20250221T140456
[2025-02-21T14:04:56.442+0000] {local_task_job.py:208} INFO - Task exited with return code 0
[2025-02-21T14:04:56.567+0000] {taskinstance.py:2578} INFO - 2 downstream tasks scheduled from follow-on schedule check
[2025-02-21T14:25:16.725+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: listenbrainz_dynamic_pipeline.list_new_files scheduled__2025-01-01T00:00:00+00:00 [queued]>
[2025-02-21T14:25:16.732+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: listenbrainz_dynamic_pipeline.list_new_files scheduled__2025-01-01T00:00:00+00:00 [queued]>
[2025-02-21T14:25:16.732+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2025-02-21T14:25:16.732+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 2
[2025-02-21T14:25:16.732+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2025-02-21T14:25:16.742+0000] {taskinstance.py:1300} INFO - Executing <Task(_PythonDecoratedOperator): list_new_files> on 2025-01-01 00:00:00+00:00
[2025-02-21T14:25:16.745+0000] {standard_task_runner.py:55} INFO - Started process 274 to run task
[2025-02-21T14:25:16.746+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'listenbrainz_dynamic_pipeline', 'list_new_files', 'scheduled__2025-01-01T00:00:00+00:00', '--job-id', '5', '--raw', '--subdir', 'DAGS_FOLDER/listenbrainz_dag.py', '--cfg-path', '/tmp/tmp1x86d2lw']
[2025-02-21T14:25:16.747+0000] {standard_task_runner.py:83} INFO - Job 5: Subtask list_new_files
[2025-02-21T14:25:16.796+0000] {task_command.py:388} INFO - Running <TaskInstance: listenbrainz_dynamic_pipeline.list_new_files scheduled__2025-01-01T00:00:00+00:00 [running]> on host 67bebaff4560
[2025-02-21T14:25:16.850+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=listenbrainz_dynamic_pipeline
AIRFLOW_CTX_TASK_ID=list_new_files
AIRFLOW_CTX_EXECUTION_DATE=2025-01-01T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2025-01-01T00:00:00+00:00
[2025-02-21T14:25:16.851+0000] {listenbrainz_dag.py:45} INFO - Found JSON files: ['/data/raw/sample-data-2.json', '/data/raw/sample-data-3.json', '/data/raw/sample-data.json']
[2025-02-21T14:25:16.851+0000] {python.py:177} INFO - Done. Returned value was: ['/data/raw/sample-data-2.json', '/data/raw/sample-data-3.json', '/data/raw/sample-data.json']
[2025-02-21T14:25:16.875+0000] {taskinstance.py:1323} INFO - Marking task as SUCCESS. dag_id=listenbrainz_dynamic_pipeline, task_id=list_new_files, execution_date=20250101T000000, start_date=20250221T142516, end_date=20250221T142516
[2025-02-21T14:25:16.918+0000] {local_task_job.py:208} INFO - Task exited with return code 0
[2025-02-21T14:25:16.996+0000] {taskinstance.py:2578} INFO - 3 downstream tasks scheduled from follow-on schedule check
